env_name: 'HitBackEnv'
mode: 'online'
group: '16_09_cl_reward/continue0909/against0829'
render: False
record: False

adv_bonus: 0.1
#n_episodes: 100
n_steps: 20000
n_epochs: 100
horizon: 600
n_steps_per_fit: 1
num_adv_sample: 50
initial_replay_size: 20000
max_replay_size: 1000000
warmup_transitions: 20000
termination_warmup: 20000
batch_size: 256
tau: 0.003
dropout_ratio: 0.01
layer_norm: False
#n_eval_episodes: 10
n_eval_steps: 5000
full_save: False
agent_buffer_length: 4

#lr_alpha: 0.00001
#actor_lr: 0.0003
gamma: 0.995
lr_alpha: 0.00001
actor_lr: 0.0003
critic_lr: 0.0003
termination_lr: 0.00001
target_entropy: -2

task_curriculum: True
curriculum_steps: 5

check_point__: "t_sac_2024-09-09_00-23-22/parallel_seed___0/0/HitBackEnv_2024-09-09-03-23-16"

sweep_params:
  parallel_seed__: [0]


experiments:
  exp_name: 't_sac'
  exp_file: 'train_t_sac_exp'
  n_seeds: 1
  n_cores: 4
  n_exps_in_parallel: 1
  memory_single_job: 5000
  days: 0
  hours: 23
  minutes: 59
  seconds: 0
  partition: 'stud3080'
  gres: 'gpu:1'   # if use_cuda 'gpu:1'
  conda_env: 'neural_planner'
  use_timestamp: True
  compact_dirs: False
  use_cuda: True



